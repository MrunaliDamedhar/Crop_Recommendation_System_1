import pandas as pd
import joblib
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

# Load dataset
df = pd.read_csv('Crop_recommendation.csv')

# Split features/labels
X = df.drop('label', axis=1)
y = df['label']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=1
)

# Train models
log_model = LogisticRegression(max_iter=200)
log_model.fit(X_train, y_train)
log_acc = accuracy_score(y_test, log_model.predict(X_test))

dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)
dt_acc = accuracy_score(y_test, dt_model.predict(X_test))

rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)
rf_acc = accuracy_score(y_test, rf_model.predict(X_test))

print("Logistic Regression Accuracy:", log_acc)
print("Decision Tree Accuracy:", dt_acc)
print("Random Forest Accuracy:", rf_acc)

# Select BEST model
best_model = rf_model   # Random Forest is best for crop dataset

# Save model properly
joblib.dump(best_model, "crop_model.pkl")
print("Model saved as crop_model.pkl")

# Test prediction
sample = [[90, 42, 43, 20.879744, 82.002744, 6.50, 202.935536]]
loaded_model = joblib.load("crop_model.pkl")
print("Prediction:", loaded_model.predict(sample))
